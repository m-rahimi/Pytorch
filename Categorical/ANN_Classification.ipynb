{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Classification\n",
    "\n",
    "I want to use embedding model to handel categorical features for a binary classification problem. see <a href='https://www.kaggle.com/c/cat-in-the-dat/'>Kaggle competition</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...        nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...    2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...    f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...    ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...    8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...    b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/cat.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (3, 2), (6, 3), (6, 3), (6, 3), (4, 2), (222, 50), (522, 50), (1220, 50), (2215, 50), (11981, 50), (3, 2), (5, 3), (6, 3), (15, 8), (26, 13), (192, 50), (7, 4), (12, 6)]\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "cats = list(df.columns.values)\n",
    "cats.remove('target')\n",
    "\n",
    "for cat in cats:\n",
    "    df[cat] = df[cat].astype('category')\n",
    "    \n",
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cats]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "print(emb_szs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features with low cardiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_4', 'ord_5']\n",
      "['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'ord_0', 'ord_1', 'ord_2', 'ord_3', 'day', 'month']\n",
      "[(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (3, 2), (6, 3), (6, 3), (6, 3), (4, 2), (3, 2), (5, 3), (6, 3), (15, 8), (7, 4), (12, 6)]\n"
     ]
    }
   ],
   "source": [
    "drops =[]\n",
    "for col, emb in zip(cats, emb_szs):\n",
    "    if emb[1]>10:\n",
    "        drops.append(col)\n",
    "print(drops)\n",
    "cats = [x for x in cats if x not in drops]\n",
    "print(cats)\n",
    "        \n",
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cats]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "print(emb_szs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cats:\n",
    "    df[cat] = df[cat].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30588"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dt, target, cats=None, IDs=None, size=None, seed=123):\n",
    "        'Initialization'\n",
    "        if IDs is None:\n",
    "            np.random.seed(seed)\n",
    "            self.ids = list(np.where(np.random.rand(dt.shape[0]) < size)[0])\n",
    "            print('len of dataset: '+str(len(self.ids)))\n",
    "        else:\n",
    "            self.ids = IDs\n",
    "        \n",
    "        self.target = torch.from_numpy(dt[target][self.ids].values.astype(np.int64)).flatten() #.reshape(-1,1))\n",
    "        dt = dt.drop(target, axis=1)\n",
    "        if cats is not None:\n",
    "            self.cats  = torch.from_numpy(dt[cats].iloc[self.ids].values.astype(np.int64))\n",
    "            dt = dt.drop(cats, axis=1)\n",
    "        if dt.shape[0] > 0:\n",
    "            self.data  = torch.from_numpy(dt.iloc[self.ids].values.astype(np.float32))\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "#        print(index, self.data[index])\n",
    "\n",
    "        return self.data[index], self.cats[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149760 150240\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 10000,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "np.random.seed(123)\n",
    "size = 0.5\n",
    "rand = np.random.rand(df.shape[0])\n",
    "train_ids = list(np.where(rand < size)[0])\n",
    "test_ids = list(np.where(rand >= size)[0])\n",
    "\n",
    "print(len(train_ids), len(test_ids))\n",
    "\n",
    "training_set = Dataset(df[cats+['target']], 'target', cats=cats, IDs=train_ids)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = Dataset(df[cats+['target']], 'target', cats=cats, IDs=test_ids)\n",
    "testing_generator = data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "    (4): Embedding(2, 1)\n",
       "    (5): Embedding(3, 2)\n",
       "    (6): Embedding(6, 3)\n",
       "    (7): Embedding(6, 3)\n",
       "    (8): Embedding(6, 3)\n",
       "    (9): Embedding(4, 2)\n",
       "    (10): Embedding(3, 2)\n",
       "    (11): Embedding(5, 3)\n",
       "    (12): Embedding(6, 3)\n",
       "    (13): Embedding(15, 8)\n",
       "    (14): Embedding(7, 4)\n",
       "    (15): Embedding(12, 6)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=10, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, 2, [10], p=0.4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.87303334  auc: 0.55625808\n",
      "epoch:   3  loss: 0.84311676  auc: 0.58077575\n",
      "epoch:   5  loss: 0.82545984  auc: 0.59362099\n",
      "epoch:   7  loss: 0.81419414  auc: 0.59871633\n",
      "epoch:   9  loss: 0.80374485  auc: 0.60800365\n",
      "epoch:  11  loss: 0.79543352  auc: 0.61445643\n",
      "epoch:  13  loss: 0.78801525  auc: 0.62219480\n",
      "epoch:  15  loss: 0.78267097  auc: 0.62476562\n",
      "epoch:  17  loss: 0.77754110  auc: 0.63200862\n",
      "epoch:  19  loss: 0.77440000  auc: 0.63501082\n",
      "epoch:  21  loss: 0.77129209  auc: 0.64194526\n",
      "epoch:  23  loss: 0.76949745  auc: 0.64503570\n",
      "epoch:  25  loss: 0.76781851  auc: 0.64877689\n",
      "epoch:  27  loss: 0.76625645  auc: 0.65258500\n",
      "epoch:  29  loss: 0.76502997  auc: 0.65629568\n",
      "epoch:  31  loss: 0.76391059  auc: 0.65933735\n",
      "epoch:  33  loss: 0.76343554  auc: 0.66017238\n",
      "epoch:  35  loss: 0.76288426  auc: 0.66202923\n",
      "epoch:  37  loss: 0.76204658  auc: 0.66511636\n",
      "epoch:  39  loss: 0.76139408  auc: 0.66678512\n",
      "epoch:  41  loss: 0.76104212  auc: 0.66809907\n",
      "epoch:  43  loss: 0.76030177  auc: 0.66990042\n",
      "epoch:  45  loss: 0.76011938  auc: 0.67118970\n",
      "epoch:  47  loss: 0.76022285  auc: 0.67073882\n",
      "epoch:  49  loss: 0.75944102  auc: 0.67255918\n",
      "epoch:  51  loss: 0.75879395  auc: 0.67548570\n",
      "epoch:  53  loss: 0.75923789  auc: 0.67341109\n",
      "epoch:  55  loss: 0.75840110  auc: 0.67619823\n",
      "epoch:  57  loss: 0.75848633  auc: 0.67569670\n",
      "epoch:  59  loss: 0.75780618  auc: 0.67805368\n",
      "epoch:  61  loss: 0.75725651  auc: 0.67977947\n",
      "epoch:  63  loss: 0.75755602  auc: 0.67895759\n",
      "epoch:  65  loss: 0.75715578  auc: 0.68009360\n",
      "epoch:  67  loss: 0.75716436  auc: 0.67992675\n",
      "epoch:  69  loss: 0.75659567  auc: 0.68124414\n",
      "epoch:  71  loss: 0.75716394  auc: 0.68041785\n",
      "epoch:  73  loss: 0.75663310  auc: 0.68152240\n",
      "epoch:  75  loss: 0.75584197  auc: 0.68402412\n",
      "epoch:  77  loss: 0.75659460  auc: 0.68194066\n",
      "epoch:  79  loss: 0.75616819  auc: 0.68313886\n",
      "epoch:  81  loss: 0.75612146  auc: 0.68256956\n",
      "epoch:  83  loss: 0.75571358  auc: 0.68461782\n",
      "epoch:  85  loss: 0.75519943  auc: 0.68537580\n",
      "epoch:  87  loss: 0.75544196  auc: 0.68488201\n",
      "epoch:  89  loss: 0.75514984  auc: 0.68546104\n",
      "epoch:  91  loss: 0.75557417  auc: 0.68507160\n",
      "epoch:  93  loss: 0.75538206  auc: 0.68536810\n",
      "epoch:  95  loss: 0.75498104  auc: 0.68627717\n",
      "epoch:  97  loss: 0.75512439  auc: 0.68616329\n",
      "epoch:  99  loss: 0.75469196  auc: 0.68736248\n",
      "epoch: 100  loss: 0.75514221\n",
      "\n",
      "Duration: 782 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 100\n",
    "losses1 = []\n",
    "losses2 = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    \n",
    "    for continuous, categoricals, target in training_generator:\n",
    "        y_pred = model(categoricals)\n",
    "        loss = torch.sqrt(criterion(y_pred, target))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        y_pred = model(training_set.cats)\n",
    "        loss = torch.sqrt(criterion(y_pred, training_set.target))\n",
    "        losses1.append(loss)\n",
    "        \n",
    "        y_pred = model(testing_set.cats)\n",
    "        loss = torch.sqrt(criterion(y_pred, testing_set.target))\n",
    "        losses2.append(loss)\n",
    "        \n",
    "        y_pred = pred = torch.nn.functional.softmax(y_pred, dim=1).data.numpy()\n",
    "        y_true = testing_set.target.data.numpy()\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%2 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}  auc: {auc:10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dt, target, cats=None, IDs=None, size=None, seed=123):\n",
    "        'Initialization'\n",
    "        if IDs is None:\n",
    "            np.random.seed(seed)\n",
    "            self.ids = list(np.where(np.random.rand(dt.shape[0]) < size)[0])\n",
    "            print('len of dataset: '+str(len(self.ids)))\n",
    "        else:\n",
    "            self.ids = IDs\n",
    "        \n",
    "        self.target = torch.from_numpy(dt[target][self.ids].values.astype(np.int64)).flatten() #.reshape(-1,1))\n",
    "        dt = dt.drop(target, axis=1)\n",
    "        if cats is not None:\n",
    "            self.cats  = torch.from_numpy(dt[cats].iloc[self.ids].values.astype(np.int64))\n",
    "            dt = dt.drop(cats, axis=1)\n",
    "        if dt.shape[0] > 0:\n",
    "            self.data  = torch.from_numpy(dt.iloc[self.ids].values.astype(np.float32))\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "#        print(index, self.data[index])\n",
    "\n",
    "        return self.data[index], self.cats[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((ni for ni,nf in emb_szs))\n",
    "        n_in = n_emb\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat):\n",
    "        \n",
    "        x = torch.nn.functional.one_hot(x_cat[:,0])\n",
    "        for i in range(1,x_cat.size()[1]):\n",
    "            x = torch.cat([x, torch.nn.functional.one_hot(x_cat[:,i])], 1)\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        \n",
    "        bt = nn.BatchNorm1d(x.size()[1])\n",
    "        x = bt(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149760 150240\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1000,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "np.random.seed(123)\n",
    "size = 0.5\n",
    "rand = np.random.rand(df.shape[0])\n",
    "train_ids = list(np.where(rand < size)[0])\n",
    "test_ids = list(np.where(rand >= size)[0])\n",
    "\n",
    "print(len(train_ids), len(test_ids))\n",
    "\n",
    "training_set = Dataset(df[cats+['target']], 'target', cats=cats, IDs=train_ids)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = Dataset(df[cats+['target']], 'target', cats=cats, IDs=test_ids)\n",
    "testing_generator = data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=83, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, 2, [200, 100], p=0.2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.75473785  auc: 0.69374832\n",
      "epoch:   3  loss: 0.74602073  auc: 0.70898513\n",
      "epoch:   5  loss: 0.74557894  auc: 0.71006836\n",
      "epoch:   7  loss: 0.74558628  auc: 0.70974565\n",
      "epoch:   9  loss: 0.74656123  auc: 0.70786678\n",
      "epoch:  10  loss: 0.74645495\n",
      "\n",
      "Duration: 96 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "losses1 = []\n",
    "losses2 = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    \n",
    "    for continuous, categoricals, target in training_generator:\n",
    "        y_pred = model(categoricals)\n",
    "        loss = torch.sqrt(criterion(y_pred, target))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        y_pred = model(training_set.cats)\n",
    "        loss = torch.sqrt(criterion(y_pred, training_set.target))\n",
    "        losses1.append(loss)\n",
    "        \n",
    "        y_pred = model(testing_set.cats)\n",
    "        loss = torch.sqrt(criterion(y_pred, testing_set.target))\n",
    "        losses2.append(loss)\n",
    "        \n",
    "        y_pred = pred = torch.nn.functional.softmax(y_pred, dim=1).data.numpy()\n",
    "        y_true = testing_set.target.data.numpy()\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%2 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}  auc: {auc:10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([ 0.1216, -0.5535], grad_fn=<SelectBackward>)    0      0   \n",
      "tensor([ 0.4670, -0.2198], grad_fn=<SelectBackward>)    0      1   \n",
      "tensor([ 0.1880, -0.9448], grad_fn=<SelectBackward>)    0      0   \n",
      "tensor([-0.4727, -0.3521], grad_fn=<SelectBackward>)    1      0   \n",
      "tensor([ 0.4123, -0.5494], grad_fn=<SelectBackward>)    0      0   \n",
      "\n",
      "3 out of 5 = 60.00% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 5\n",
    "correct = 0\n",
    "y_val = model(testing_set.cats)\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_true[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_true[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df,\n",
    "                         columns=df.columns,\n",
    "                         drop_first=True,\n",
    "                         sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 16439)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
